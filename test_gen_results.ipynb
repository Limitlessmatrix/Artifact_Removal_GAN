{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.tensorboard import *\n",
    "from fastai.vision.gan import *\n",
    "from superRes.generators import *\n",
    "from superRes.critics import *\n",
    "from superRes.dataset import *\n",
    "from superRes.loss import *\n",
    "from superRes.save import *\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from PIL import ImageFile\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import geffnet # efficient/ mobile net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs:int, sz:int, keep_pct:float):\n",
    "    return get_databunch(sz=sz, bs=bs, crappy_path=path_lowRes, \n",
    "                         good_path=path_fullRes, \n",
    "                         random_seed=None, keep_pct=keep_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "\n",
    "path_fullRes = path/'images'\n",
    "path_lowRes = path/'small-96'\n",
    "path_medRes = path/'lowRes-256'\n",
    "\n",
    "proj_id = 'unet_superRes'\n",
    "\n",
    "gen_name = proj_id + '_gen'\n",
    "crit_name = proj_id + '_crit'\n",
    "\n",
    "TENSORBOARD_PATH = Path('data/tensorboard/' + proj_id)\n",
    "\n",
    "nf_factor = 2\n",
    "pct_start = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=25\n",
    "sz=128\n",
    "lr = 1e-3\n",
    "wd = 1e-3\n",
    "keep_pct=1.0\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = get_data(bs=bs, sz=sz, keep_pct=keep_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen = gen_learner_wide(data=data_gen,\n",
    "                             gen_loss=FeatureLoss(),\n",
    "                             arch = model,\n",
    "                             nf_factor=nf_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d83cee2dc224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m learn = unet_learner(data_gen, model, wd=wd, loss_func=feat_loss, callback_fns=LossMetrics,\n\u001b[0m\u001b[1;32m      3\u001b[0m                      blur=True, norm_type=NormType.Weight)\n\u001b[1;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feat_loss' is not defined"
     ]
    }
   ],
   "source": [
    "wd = 1e-3\n",
    "learn = unet_learner(data_gen, model, wd=wd, loss_func=feat_loss, callback_fns=LossMetrics,\n",
    "                     blur=True, norm_type=NormType.Weight)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DynamicUnetWide:\n\tMissing key(s) in state_dict: \"layers.3.0.0.weight_orig\", \"layers.3.0.0.weight\", \"layers.3.0.0.weight_u\", \"layers.3.0.0.weight_orig\", \"layers.3.0.0.weight_u\", \"layers.3.0.2.weight\", \"layers.3.0.2.bias\", \"layers.3.0.2.running_mean\", \"layers.3.0.2.running_var\", \"layers.3.1.0.weight_orig\", \"layers.3.1.0.weight\", \"layers.3.1.0.weight_u\", \"layers.3.1.0.weight_orig\", \"layers.3.1.0.weight_u\", \"layers.3.1.2.weight\", \"layers.3.1.2.bias\", \"layers.3.1.2.running_mean\", \"layers.3.1.2.running_var\", \"layers.4.shuf.conv.0.weight_orig\", \"layers.4.shuf.conv.0.weight\", \"layers.4.shuf.conv.0.weight_u\", \"layers.4.shuf.conv.0.weight_orig\", \"layers.4.shuf.conv.0.weight_u\", \"layers.4.shuf.conv.1.weight\", \"layers.4.shuf.conv.1.bias\", \"layers.4.shuf.conv.1.running_mean\", \"layers.4.shuf.conv.1.running_var\", \"layers.4.conv.0.weight_orig\", \"layers.4.conv.0.weight\", \"layers.4.conv.0.weight_u\", \"layers.4.conv.0.weight_orig\", \"layers.4.conv.0.weight_u\", \"layers.4.conv.0.weight_v\", \"layers.4.conv.2.weight\", \"layers.4.conv.2.bias\", \"layers.4.conv.2.running_mean\", \"layers.4.conv.2.running_var\", \"layers.5.shuf.conv.0.weight_orig\", \"layers.5.shuf.conv.0.weight\", \"layers.5.shuf.conv.0.weight_u\", \"layers.5.shuf.conv.0.weight_orig\", \"layers.5.shuf.conv.0.weight_u\", \"layers.5.shuf.conv.1.weight\", \"layers.5.shuf.conv.1.bias\", \"layers.5.shuf.conv.1.running_mean\", \"layers.5.shuf.conv.1.running_var\", \"layers.5.conv.0.weight_orig\", \"layers.5.conv.0.weight\", \"layers.5.conv.0.weight_u\", \"layers.5.conv.0.weight_orig\", \"layers.5.conv.0.weight_u\", \"layers.5.conv.0.weight_v\", \"layers.5.conv.2.weight\", \"layers.5.conv.2.bias\", \"layers.5.conv.2.running_mean\", \"layers.5.conv.2.running_var\", \"layers.5.conv.3.gamma\", \"layers.5.conv.3.query.weight_orig\", \"layers.5.conv.3.query.weight\", \"layers.5.conv.3.query.weight_u\", \"layers.5.conv.3.query.weight_orig\", \"layers.5.conv.3.query.weight_u\", \"layers.5.conv.3.query.weight_v\", \"layers.5.conv.3.key.weight_orig\", \"layers.5.conv.3.key.weight\", \"layers.5.conv.3.key.weight_u\", \"layers.5.conv.3.key.weight_orig\", \"layers.5.conv.3.key.weight_u\", \"layers.5.conv.3.key.weight_v\", \"layers.5.conv.3.value.weight_orig\", \"layers.5.conv.3.value.weight\", \"layers.5.conv.3.value.weight_u\", \"layers.5.conv.3.value.weight_orig\", \"layers.5.conv.3.value.weight_u\", \"layers.5.conv.3.value.weight_v\", \"layers.6.shuf.conv.0.weight_orig\", \"layers.6.shuf.conv.0.weight\", \"layers.6.shuf.conv.0.weight_u\", \"layers.6.shuf.conv.0.weight_orig\", \"layers.6.shuf.conv.0.weight_u\", \"layers.6.shuf.conv.1.weight\", \"layers.6.shuf.conv.1.bias\", \"layers.6.shuf.conv.1.running_mean\", \"layers.6.shuf.conv.1.running_var\", \"layers.6.conv.0.weight_orig\", \"layers.6.conv.0.weight\", \"layers.6.conv.0.weight_u\", \"layers.6.conv.0.weight_orig\", \"layers.6.conv.0.weight_u\", \"layers.6.conv.0.weight_v\", \"layers.6.conv.2.weight\", \"layers.6.conv.2.bias\", \"layers.6.conv.2.running_mean\", \"layers.6.conv.2.running_var\", \"layers.7.shuf.conv.0.weight_orig\", \"layers.7.shuf.conv.0.weight\", \"layers.7.shuf.conv.0.weight_u\", \"layers.7.shuf.conv.0.weight_orig\", \"layers.7.shuf.conv.0.weight_u\", \"layers.7.shuf.conv.1.weight\", \"layers.7.shuf.conv.1.bias\", \"layers.7.shuf.conv.1.running_mean\", \"layers.7.shuf.conv.1.running_var\", \"layers.7.conv.0.weight_orig\", \"layers.7.conv.0.weight\", \"layers.7.conv.0.weight_u\", \"layers.7.conv.0.weight_orig\", \"layers.7.conv.0.weight_u\", \"layers.7.conv.0.weight_v\", \"layers.7.conv.2.weight\", \"layers.7.conv.2.bias\", \"layers.7.conv.2.running_mean\", \"layers.7.conv.2.running_var\", \"layers.10.layers.0.0.weight_orig\", \"layers.10.layers.0.0.weight\", \"layers.10.layers.0.0.weight_u\", \"layers.10.layers.0.0.weight_orig\", \"layers.10.layers.0.0.weight_u\", \"layers.10.layers.1.0.weight_orig\", \"layers.10.layers.1.0.weight\", \"layers.10.layers.1.0.weight_u\", \"layers.10.layers.1.0.weight_orig\", \"layers.10.layers.1.0.weight_u\", \"layers.11.0.weight_orig\", \"layers.11.0.weight\", \"layers.11.0.weight_u\", \"layers.11.0.weight_orig\", \"layers.11.0.weight_u\". \n\tUnexpected key(s) in state_dict: \"layers.3.0.0.bias\", \"layers.3.0.0.weight_g\", \"layers.3.1.0.bias\", \"layers.3.1.0.weight_g\", \"layers.4.conv1.0.bias\", \"layers.4.conv1.0.weight_g\", \"layers.4.conv1.0.weight_v\", \"layers.4.conv2.0.bias\", \"layers.4.conv2.0.weight_g\", \"layers.4.conv2.0.weight_v\", \"layers.4.shuf.conv.0.bias\", \"layers.4.shuf.conv.0.weight_g\", \"layers.5.conv1.0.bias\", \"layers.5.conv1.0.weight_g\", \"layers.5.conv1.0.weight_v\", \"layers.5.conv2.0.bias\", \"layers.5.conv2.0.weight_g\", \"layers.5.conv2.0.weight_v\", \"layers.5.shuf.conv.0.bias\", \"layers.5.shuf.conv.0.weight_g\", \"layers.6.conv1.0.bias\", \"layers.6.conv1.0.weight_g\", \"layers.6.conv1.0.weight_v\", \"layers.6.conv2.0.bias\", \"layers.6.conv2.0.weight_g\", \"layers.6.conv2.0.weight_v\", \"layers.6.shuf.conv.0.bias\", \"layers.6.shuf.conv.0.weight_g\", \"layers.7.conv1.0.bias\", \"layers.7.conv1.0.weight_g\", \"layers.7.conv1.0.weight_v\", \"layers.7.conv2.0.bias\", \"layers.7.conv2.0.weight_g\", \"layers.7.conv2.0.weight_v\", \"layers.7.shuf.conv.0.bias\", \"layers.7.shuf.conv.0.weight_g\", \"layers.10.layers.0.0.weight_g\", \"layers.10.layers.1.0.weight_g\", \"layers.11.0.weight_g\". \n\tsize mismatch for layers.3.0.0.weight_v: copying a param with shape torch.Size([1024, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([4608]).\n\tsize mismatch for layers.3.1.0.weight_v: copying a param with shape torch.Size([512, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([9216]).\n\tsize mismatch for layers.4.shuf.conv.0.weight_v: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layers.5.shuf.conv.0.weight_v: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layers.6.shuf.conv.0.weight_v: copying a param with shape torch.Size([768, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layers.7.shuf.conv.0.weight_v: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layers.8.conv.0.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layers.8.conv.0.weight_g: copying a param with shape torch.Size([384, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1, 1, 1]).\n\tsize mismatch for layers.8.conv.0.weight_v: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for layers.10.layers.0.0.bias: copying a param with shape torch.Size([99]) from checkpoint, the shape in current model is torch.Size([259]).\n\tsize mismatch for layers.10.layers.0.0.weight_v: copying a param with shape torch.Size([99, 99, 3, 3]) from checkpoint, the shape in current model is torch.Size([2331]).\n\tsize mismatch for layers.10.layers.1.0.bias: copying a param with shape torch.Size([99]) from checkpoint, the shape in current model is torch.Size([259]).\n\tsize mismatch for layers.10.layers.1.0.weight_v: copying a param with shape torch.Size([99, 99, 3, 3]) from checkpoint, the shape in current model is torch.Size([2331]).\n\tsize mismatch for layers.11.0.weight_v: copying a param with shape torch.Size([3, 99, 1, 1]) from checkpoint, the shape in current model is torch.Size([259]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6d39943ad7bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, file, device, strict, with_opt, purge, remove_module)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremove_module\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_module_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 845\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DynamicUnetWide:\n\tMissing key(s) in state_dict: \"layers.3.0.0.weight_orig\", \"layers.3.0.0.weight\", \"layers.3.0.0.weight_u\", \"layers.3.0.0.weight_orig\", \"layers.3.0.0.weight_u\", \"layers.3.0.2.weight\", \"layers.3.0.2.bias\", \"layers.3.0.2.running_mean\", \"layers.3.0.2.running_var\", \"layers.3.1.0.weight_orig\", \"layers.3.1.0.weight\", \"layers.3.1.0.weight_u\", \"layers.3.1.0.weight_orig\", \"layers.3.1.0.weight_u\", \"layers.3.1.2.weight\", \"layers.3.1.2.bias\", \"layers.3.1.2.running_mean\", \"layers.3.1.2.running_var\", \"layers.4.shuf.conv.0.weight_orig\", \"layers.4.shuf.conv.0.weight\", \"layers.4.shuf.conv.0.weight_u\", \"layers.4.shuf.conv.0.weight_orig\", \"layers.4.shuf.conv.0.weight_u\", \"layers.4.shuf.conv.1.weight\", \"layers.4.shuf.conv.1.bias\", \"layers.4.shuf.conv.1.running_mean\", \"layers.4.shuf.conv.1.running_var\", \"layers.4.conv.0.weight_orig\", \"layers.4.conv.0.weight\", \"layers.4.conv.0.weight_u\", \"layers.4.conv.0.weight_orig\", \"layers.4.conv.0.weight_u\", \"layers.4.conv.0.weight_v\", \"layers.4.conv.2.weight\", \"layers.4.conv.2.bias\", \"layers.4.conv.2.running_mean\", \"layers.4.conv.2.running_var\", \"layers.5.shuf.conv.0.weight_orig\", \"layers.5.shuf.conv.0.weight\", \"layers.5.shuf.conv.0.weight_u\", \"layers.5.shuf.conv.0.weight_orig\", \"layers.5.shuf.conv.0.weight_u\", \"layers.5.shuf.conv.1.weight\", \"layers.5.shuf.conv.1.bias\", \"layers.5.shuf.conv.1.running_mean\", \"layers.5.shuf.conv.1.running_var\", \"layers.5.conv.0.weight_orig\", \"layers.5.conv.0.weight\", \"layers.5.conv.0.weight_u\", \"layers.5.conv.0.weight_orig\", \"layers.5.conv.0.weight_u\", \"layers.5.conv.0.weight_v\", \"layers.5.conv.2.weight\", \"layers.5.conv.2.bias\", \"layers.5.conv.2.running_mean\", \"layers.5.conv.2.running_var\", \"layers.5.conv.3.gamma\", \"layers.5.conv.3.query.weight_orig\", \"layers.5.conv.3.query.weight\", \"layers.5.conv.3.query.weight_u\", \"layers.5.conv.3.query.weight_orig\", \"layers.5.conv.3.query.weight_u\", \"layers.5.conv.3.query.weight_v\", \"layers.5.conv.3.key.weight_orig\", \"layers.5.conv.3.key.weight\", \"layers.5.conv.3.key.weight_u\", \"layers.5.conv.3.key.weight_orig\", \"layers.5.conv.3.key.weight_u\", \"layers.5.conv.3.key.weight_v\", \"layers.5.conv.3.value.weight_orig\", \"layers.5.conv.3.value.weight\", \"layers.5.conv.3.value.weight_u\", \"layers.5.conv.3.value.weight_orig\", \"layers.5.conv.3.value.weight_u\", \"layers.5.conv.3.value.weight_v\", \"layers.6.shuf.conv.0.weight_orig\", \"layers.6.shuf.conv.0.weight\", \"layers.6.shuf.conv.0.weight_u\", \"layers.6.shuf.conv.0.weight_orig\", \"layers.6.shuf.conv.0.weight_u\", \"layers.6.shuf.conv.1.weight\", \"layers.6.shuf.conv.1.bias\", \"layers.6.shuf.conv.1.running_mean\", \"layers.6.shuf.conv.1.running_var\", \"layers.6.conv.0.weight_orig\", \"layers.6.conv.0.weight\", \"layers.6.conv.0.weight_u\", \"layers.6.conv.0.weight_orig\", \"layers.6.conv.0.weight_u\", \"layers.6.conv.0.weight_v\", \"layers.6.conv.2.weight\", \"layers.6.conv.2.bias\", \"layers.6.conv.2.running_mean\", \"layers.6.conv.2.running_var\", \"layers.7.shuf.conv.0.weight_orig\", \"layers.7.shuf.conv.0.weight\", \"layers.7.shuf.conv.0.weight_u\", \"layers.7.shuf.conv.0.weight_orig\", \"layers.7.shuf.conv.0.weight_u\", \"layers.7.shuf.conv.1.weight\", \"layers.7.shuf.conv.1.bias\", \"layers.7.shuf.conv.1.running_mean\", \"layers.7.shuf.conv.1.running_var\", \"layers.7.conv.0.weight_orig\", \"layers.7.conv.0.weight\", \"layers.7.conv.0.weight_u\", \"layers.7.conv.0.weight_orig\", \"layers.7.conv.0.weight_u\", \"layers.7.conv.0.weight_v\", \"layers.7.conv.2.weight\", \"layers.7.conv.2.bias\", \"layers.7.conv.2.running_mean\", \"layers.7.conv.2.running_var\", \"layers.10.layers.0.0.weight_orig\", \"layers.10.layers.0.0.weight\", \"layers.10.layers.0.0.weight_u\", \"layers.10.layers.0.0.weight_orig\", \"layers.10.layers.0.0.weight_u\", \"layers.10.layers.1.0.weight_orig\", \"layers.10.layers.1.0.weight\", \"layers.10.layers.1.0.weight_u\", \"layers.10.layers.1.0.weight_orig\", \"layers.10.layers.1.0.weight_u\", \"layers.11.0.weight_orig\", \"layers.11.0.weight\", \"layers.11.0.weight_u\", \"layers.11.0.weight_orig\", \"layers.11.0.weight_u\". \n\tUnexpected key(s) in state_dict: \"layers.3.0.0.bias\", \"layers.3.0.0.weight_g\", \"layers.3.1.0.bias\", \"layers.3.1.0.weight_g\", \"layers.4.conv1.0.bias\", \"layers.4.conv1.0.weight_g\", \"layers.4.conv1.0.weight_v\", \"layers.4.conv2.0.bias\", \"layers.4.conv2.0.weight_g\", \"layers.4.conv2.0.weight_v\", \"layers.4.shuf.conv.0.bias\", \"layers.4.shuf.conv.0.weight_g\", \"layers.5.conv1.0.bias\", \"layers.5.conv1.0.weight_g\", \"layers.5.conv1.0.weight_v\", \"layers.5.conv2.0.bias\", \"layers.5.conv2.0.weight_g\", \"layers.5.conv2.0.weight_v\", \"layers.5.shuf.conv.0.bias\", \"layers.5.shuf.conv.0.weight_g\", \"layers.6.conv1.0.bias\", \"layers.6.conv1.0.weight_g\", \"layers.6.conv1.0.weight_v\", \"layers.6.conv2.0.bias\", \"layers.6.conv2.0.weight_g\", \"layers.6.conv2.0.weight_v\", \"layers.6.shuf.conv.0.bias\", \"layers.6.shuf.conv.0.weight_g\", \"layers.7.conv1.0.bias\", \"layers.7.conv1.0.weight_g\", \"layers.7.conv1.0.weight_v\", \"layers.7.conv2.0.bias\", \"layers.7.conv2.0.weight_g\", \"layers.7.conv2.0.weight_v\", \"layers.7.shuf.conv.0.bias\", \"layers.7.shuf.conv.0.weight_g\", \"layers.10.layers.0.0.weight_g\", \"layers.10.layers.1.0.weight_g\", \"layers.11.0.weight_g\". \n\tsize mismatch for layers.3.0.0.weight_v: copying a param with shape torch.Size([1024, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([4608]).\n\tsize mismatch for layers.3.1.0.weight_v: copying a param with shape torch.Size([512, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([9216]).\n\tsize mismatch for layers.4.shuf.conv.0.weight_v: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layers.5.shuf.conv.0.weight_v: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layers.6.shuf.conv.0.weight_v: copying a param with shape torch.Size([768, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layers.7.shuf.conv.0.weight_v: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layers.8.conv.0.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layers.8.conv.0.weight_g: copying a param with shape torch.Size([384, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1, 1, 1]).\n\tsize mismatch for layers.8.conv.0.weight_v: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for layers.10.layers.0.0.bias: copying a param with shape torch.Size([99]) from checkpoint, the shape in current model is torch.Size([259]).\n\tsize mismatch for layers.10.layers.0.0.weight_v: copying a param with shape torch.Size([99, 99, 3, 3]) from checkpoint, the shape in current model is torch.Size([2331]).\n\tsize mismatch for layers.10.layers.1.0.bias: copying a param with shape torch.Size([99]) from checkpoint, the shape in current model is torch.Size([259]).\n\tsize mismatch for layers.10.layers.1.0.weight_v: copying a param with shape torch.Size([99, 99, 3, 3]) from checkpoint, the shape in current model is torch.Size([2331]).\n\tsize mismatch for layers.11.0.weight_v: copying a param with shape torch.Size([3, 99, 1, 1]) from checkpoint, the shape in current model is torch.Size([259])."
     ]
    }
   ],
   "source": [
    "learn_gen.load(\"2b\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.show_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
